{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "922c5c82",
   "metadata": {},
   "source": [
    "## importing chromadb library \n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecbce2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import uuid\n",
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc3df1",
   "metadata": {},
   "source": [
    "## creating collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d402dfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'policies' already exists. Using existing collection.\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"policies\"\n",
    "\n",
    "# Check if a collection with this name already exists\n",
    "existing_collections = client.list_collections()\n",
    "existing_names = [c.name for c in existing_collections]\n",
    "\n",
    "if collection_name in existing_names:\n",
    "    collection = client.get_collection(name=collection_name)\n",
    "    print(f\"Collection '{collection_name}' already exists. Using existing collection.\")\n",
    "else:\n",
    "    collection = client.create_collection(name=collection_name)\n",
    "    print(f\"Collection '{collection_name}' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "185dfe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total paragraphs (chunks) found: 33\n",
      "Policy paragraphs added to Chroma collection.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load the full policies text from file\n",
    "with open(\"policies.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    policy_text = f.read()\n",
    "\n",
    "# 2. Split into paragraph-level chunks (separated by blank lines)\n",
    "raw_chunks = [p.strip() for p in policy_text.split(\"\\n\\n\") if p.strip()]\n",
    "print(f\"Total paragraphs (chunks) found: {len(raw_chunks)}\")\n",
    "\n",
    "# 3. Initialize the embedding model (once per notebook)\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 4. Generate UUID ids for each chunk\n",
    "ids = [str(uuid.uuid4()) for _ in raw_chunks]\n",
    "\n",
    "# 5. Embed each chunk\n",
    "embeddings = model.encode(raw_chunks).tolist()  # list of [dim]-vectors\n",
    "\n",
    "# 6. Add all chunks to the 'policies' collection\n",
    "collection.add(\n",
    "    ids=ids,\n",
    "    documents=raw_chunks,\n",
    "    embeddings=embeddings,\n",
    "    metadatas=[{\"source\": \"policies.txt\", \"type\": \"paragraph\"} for _ in raw_chunks],\n",
    ")\n",
    "\n",
    "print(\"Policy paragraphs added to Chroma collection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "193687bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1\n",
      "Distance: 0.7526344060897827\n",
      "Metadata: {'type': 'paragraph', 'source': 'policies.txt'}\n",
      "Document:\n",
      " 4. Returns, Exchanges, and Refunds\n",
      "General Return Policy:\n",
      "- Most unopened items in new and resalable condition may be returned within 30 days of purchase with an original receipt.\n",
      "- Refunds will be issued to the original form of payment or as store credit, at the Store’s discretion.\n",
      "- Items without a receipt may be refunded as store credit at the lowest selling price in the last 60 days, subject to manager approval.\n",
      "--------------------------------------------------------------------------------\n",
      "Result 2\n",
      "Distance: 0.7526344060897827\n",
      "Metadata: {'type': 'paragraph', 'source': 'policies.txt'}\n",
      "Document:\n",
      " 4. Returns, Exchanges, and Refunds\n",
      "General Return Policy:\n",
      "- Most unopened items in new and resalable condition may be returned within 30 days of purchase with an original receipt.\n",
      "- Refunds will be issued to the original form of payment or as store credit, at the Store’s discretion.\n",
      "- Items without a receipt may be refunded as store credit at the lowest selling price in the last 60 days, subject to manager approval.\n",
      "--------------------------------------------------------------------------------\n",
      "Result 3\n",
      "Distance: 0.9875897765159607\n",
      "Metadata: {'type': 'paragraph', 'source': 'policies.txt'}\n",
      "Document:\n",
      " Non-Returnable Items:\n",
      "The following items are generally not eligible for return or exchange, unless required by law:\n",
      "- Perishable goods (such as fresh food, produce, or bakery items)\n",
      "- Opened personal care items (such as cosmetics, razors, toothbrushes)\n",
      "- Intimate apparel and swimwear once worn or with tags removed\n",
      "- Gift cards and prepaid cards\n",
      "- Clearance items marked “Final Sale”\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Query the policies collection with a natural language question\n",
    "query_text = \"What is the return policy?\"\n",
    "\n",
    "# Embed the query\n",
    "query_embedding = model.encode([query_text]).tolist()\n",
    "\n",
    "# Retrieve the top-k most similar paragraphs from Chroma\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=3,\n",
    ")\n",
    "\n",
    "# Pretty-print the results\n",
    "for i, (doc, meta, dist) in enumerate(zip(results[\"documents\"][0], results[\"metadatas\"][0], results[\"distances\"][0])):\n",
    "    print(f\"Result {i+1}\")\n",
    "    print(\"Distance:\", dist)\n",
    "    print(\"Metadata:\", meta)\n",
    "    print(\"Document:\\n\", doc)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bbc3a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini LLM (gemini-2.5-flash) initialized.\n"
     ]
    }
   ],
   "source": [
    "# Configure Gemini LLM using API key from .env\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY not set in .env. Please edit .env and set GEMINI_API_KEY=your_actual_key.\")\n",
    "\n",
    "# Configure Gemini client\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Use the specified Gemini model\n",
    "llm = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "print(\"Gemini LLM (gemini-2.5-flash) initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a005fbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most unopened items in new and resalable condition may be returned within 30 days of purchase with an original receipt.\n"
     ]
    }
   ],
   "source": [
    "# RAG-style helper: retrieve from Chroma, then answer with Gemini\n",
    "\n",
    "def answer_policies_question(question: str, k: int = 3) -> str:\n",
    "    \"\"\"Retrieve top-k policy paragraphs relevant to the question and ask Gemini to answer.\n",
    "\n",
    "    Assumes:\n",
    "    - `collection` is a Chroma collection with policy paragraphs.\n",
    "    - `model` is the SentenceTransformer embedding model.\n",
    "    - `llm` is the configured Gemini GenerativeModel.\n",
    "    \"\"\"\n",
    "    # 1. Embed the question\n",
    "    query_embedding = model.encode([question]).tolist()\n",
    "\n",
    "    # 2. Retrieve top-k paragraphs from Chroma\n",
    "    results = collection.query(\n",
    "        query_embeddings=query_embedding,\n",
    "        n_results=k,\n",
    "    )\n",
    "\n",
    "    retrieved_docs = results[\"documents\"][0]\n",
    "\n",
    "    # 3. Build a context string from the retrieved paragraphs\n",
    "    context = \"\\n\\n\".join(retrieved_docs)\n",
    "\n",
    "    # 4. Construct a prompt for Gemini\n",
    "    prompt = f\"\"\"You are a helpful assistant for a retail store.\n",
    "Use ONLY the information in the CONTEXT section below to answer the QUESTION.\n",
    "If the answer is not clearly present in the context, say that you don't know based on the given policies.\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "Answer clearly and concisely.\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.generate_content(prompt)\n",
    "\n",
    "    # `response.text` is usually the main text answer. Fallback to str(response) if needed.\n",
    "    return getattr(response, \"text\", str(response))\n",
    "\n",
    "\n",
    "# Example usage (you can change the question text and re-run):\n",
    "example_answer = answer_policies_question(\"What is the return policy on unopened items?\", k=3)\n",
    "print(example_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
